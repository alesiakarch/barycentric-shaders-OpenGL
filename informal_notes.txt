

ASE Design Doc

So i wanna make a standalone tool that makes NPR render of a custom model. 

What does it need to do:

1. Initialise a 3D OpenGL scene - can do now
2. Load myMesh - comandline arguments???? 
3. Process the shaders and apply the look to the model 

That doesnt sound like a lot of functionality, maybe I should add controls for mesh selection and colour/light control? It should still process the textures based on define stylistic reference (which i dont know how to achieve) - barycentric shaders seem to clamp the values so they can have more colour options and not run into NANs, but how do i actually get the brushstrokes out of it? 

should i add some sliders for look control? We are already using Qt window anyway.

apparently i am supposed to define render passes separaely, which makes sense - I can define shaders separately for normal, AO, diffuse, etc. However, I still need to get the painted look and im not sure how that works on it...

I know that any image can be used as reference image, but how the data is pulled from it? It is not a direct projection. The paper mentioned the B-splines are somehow involved??? 

The passes then get multiplied to get the overlay image, and the reference inmage is a weight image, but how does it actually extract the data. 

Does the B-spline function calculate how to apply colour information from one image to another? 

maybe try using the charcoal reference images, those seem to have all the references provided, just inplement the colour adjustment on top, so it looks like pastel. 

Charcoal rendering pipeline order: 
1. base image
2. shadow
3. outlines
4. mirror reflections
5. specular

there is a sum for the Barycentric shader rendering equation. I assume I just feed it into the fragment shader and it calculates the thing? I dont think it will compute the reference images by itself, then what the B-splines are for??


generate separate passes into textures then load them into the new texture, calculate the final output, which then will go into the frame buffer. 
essentially, you are depicting an "comped image" to the opengl screen, not the true 3D maya scene. 
